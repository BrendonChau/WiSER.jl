<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>WiSER.jl · WiSER.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">WiSER.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>WiSER.jl</a><ul class="internal"><li><a class="tocitem" href="#Model"><span>Model</span></a></li><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Example-data"><span>Example data</span></a></li><li><a class="tocitem" href="#Formulate-model"><span>Formulate model</span></a></li><li><a class="tocitem" href="#Fit-model"><span>Fit model</span></a></li><li><a class="tocitem" href="#Tips-for-improving-estimation"><span>Tips for improving estimation</span></a></li><li><a class="tocitem" href="#Simulating-responses"><span>Simulating responses</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>WiSER.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>WiSER.jl</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/OpenMendel/WiSER.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="WiSER.jl"><a class="docs-heading-anchor" href="#WiSER.jl">WiSER.jl</a><a id="WiSER.jl-1"></a><a class="docs-heading-anchor-permalink" href="#WiSER.jl" title="Permalink"></a></h1><p><code>WiSER.jl</code> implements a regression method for modeling the within-subject variability of a longitudinal measurement. It stands for <strong>wi</strong>thin-<strong>s</strong>ubject variance <strong>e</strong>stimation by robust <strong>r</strong>egression. </p><h2 id="Model"><a class="docs-heading-anchor" href="#Model">Model</a><a id="Model-1"></a><a class="docs-heading-anchor-permalink" href="#Model" title="Permalink"></a></h2><p>TODO: don&#39;t need to give this much details. Make it clear what kind of problems it solves (a diagram will be perfect) and cite preprint will be enough.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>This package requires Julia v1.0 or later, which can be obtained from https://julialang.org/downloads/ or by building Julia from the sources in the https://github.com/JuliaLang/julia repository.</p><p>The package has not yet been registered and must be installed using the repository location. Start Julia and use the ] key to switch to the package manager REPL</p><pre><code class="language-">(@v1.4) Pkg&gt; add https://github.com/OpenMendel/WiSER.jl</code></pre><p>Use the backspace key to return to the Julia REPL.</p><pre><code class="language-julia"># for this tutorial
using CSV, DataFrames, JuliaDB, Random, WiSER</code></pre><h2 id="Example-data"><a class="docs-heading-anchor" href="#Example-data">Example data</a><a id="Example-data-1"></a><a class="docs-heading-anchor-permalink" href="#Example-data" title="Permalink"></a></h2><p>The example dataset, <code>sbp.csv</code>, is contained in <code>data</code> folder of the package. It is a simulated datatset with 500 individuals, each having 9~11 observations. The outcome, systolic blood pressure (SBP), is a function of other covariates. Below we read in the data as a <code>DataFrame</code> using the <a href="https://juliadata.github.io/CSV.jl">CSV package</a>. WiSER.jl can take other data table objects, such as <code>IndexedTables</code> from the <a href="https://github.com/JuliaData/JuliaDB.jl">JuliaDB</a> package.</p><pre><code class="language-julia">filepath = normpath(joinpath(dirname(pathof(WiSER)), &quot;../data/&quot;))
df = DataFrame!(CSV.File(filepath * &quot;sbp.csv&quot;))</code></pre><p>&lt;table class=&quot;data-frame&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;id&lt;/th&gt;&lt;th&gt;sbp&lt;/th&gt;&lt;th&gt;agegroup&lt;/th&gt;&lt;th&gt;gender&lt;/th&gt;&lt;th&gt;bmi&lt;/th&gt;&lt;th&gt;meds&lt;/th&gt;&lt;th&gt;bmi_std&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Int64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;String&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;String&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;5,011 rows × 7 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;159.586&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;23.1336&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-1.57733&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;161.849&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;26.5885&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;1.29927&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;160.484&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.8428&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.154204&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;161.134&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.9289&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.0825105&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;5&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;165.443&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.8057&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.185105&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;6&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;160.053&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.1583&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.72415&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;7&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;162.1&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.2543&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.188379&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;8&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;163.153&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.3951&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.527037&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;9&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;166.675&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;26.1514&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.935336&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;10&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;130.765&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;22.6263&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-1.99977&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;11&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;131.044&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.7404&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.239477&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;12&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;131.22&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.3415&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.260949&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;13&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;131.96&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.6933&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.553886&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;14&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;130.09&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;21.7646&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-2.71724&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;15&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;130.556&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;23.7895&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-1.03123&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;16&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;132.001&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;26.9103&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;1.56716&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;17&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;131.879&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.1153&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.759929&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;18&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;131.609&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.3372&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.257432&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;19&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;132.149&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;23.7171&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-1.09154&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;20&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;130.653&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.5947&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.471793&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;21&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;145.655&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.3645&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.280102&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;22&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;147.384&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;26.6756&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;1.37179&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;23&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;146.558&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.6001&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.476309&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;24&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;146.731&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;26.3532&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;1.10337&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;25&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;143.037&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.4092&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.515285&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;26&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;144.845&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.1193&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.075975&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;27&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;145.366&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.5029&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.395354&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;28&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;145.506&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.9668&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;0.781658&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;29&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;143.155&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;24.9327&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.0793522&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;30&lt;/th&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;146.147&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;Male&lt;/td&gt;&lt;td&gt;25.0029&lt;/td&gt;&lt;td&gt;NoMeds&lt;/td&gt;&lt;td&gt;-0.020953&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&amp;vellip;&lt;/th&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;td&gt;&amp;vellip;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</p><h2 id="Formulate-model"><a class="docs-heading-anchor" href="#Formulate-model">Formulate model</a><a id="Formulate-model-1"></a><a class="docs-heading-anchor-permalink" href="#Formulate-model" title="Permalink"></a></h2><p>First we will create a <code>WSVarLmmModel</code> object from the dataframe.</p><p>The <code>WSVarLmmModel()</code> function takes the following arguments: </p><ul><li><code>meanformula</code>: the formula for the mean fixed effects β (variables in X matrix).</li><li><code>reformula</code>: the formula for the mean random effects γ (variables in Z matrix).</li><li><code>wsvarformula</code>: the formula  for the within-subject variance fixed effects τ (variables in W matrix). </li><li><code>idvar</code>: the id variable for groupings. </li><li><code>datatable</code>: the datatable holding all of the data for the model. Can be a <code>DataFrame</code> or various types of tables such as an <code>IndexedTable</code>.</li><li><code>wtvar</code>: Optional argument of variable name holding subject-level weights in the <code>datatable</code>.</li></ul><p>For documentation of the <code>WSVarLmmModel</code> function, type <code>?WSVarLmmModel</code> in Julia REPL.</p><article class="docstring"><header><a class="docstring-binding" id="WiSER.WSVarLmmModel" href="#WiSER.WSVarLmmModel"><code>WiSER.WSVarLmmModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WSVarLmmModel</code></pre><p>Within-subject variance linear mixed model, which contains a vector of  <code>WSVarLmmObs</code> as data, model parameters, and working arrays.</p><pre><code class="language-none">WSVarLmmModel(obsvec; obswts, meannames, renames, wsvarnames)</code></pre><p><strong>Positional arguments</strong></p><ul><li><code>obsvec</code>: Vector of WSVarLmmObs</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>obswts</code>: Subject-level weight vector of observation weights, length of the <code>obsvec</code> object.</li><li><code>meannames</code>: Names of the mean fixed effects covariates</li><li><code>renames</code>: Names of the random location effects covariates</li><li><code>wsvarnames</code>: Names of the ws variance fixed effects covariates</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/OpenMendel/WiSER.jl/blob/6c5d86c93f3b6d38ec6ab3e32b66f51e08cda0a1/src/WiSER.jl#L213-L230">source</a></section></article><p>We will model sbp as a function of age, gender, and bmi<em>std. `bmi</em>std<code>is the centered and scaled</code>bmi`. The following commands fit the following model:</p><div>\[\text{sbp}_{ij} = \beta_0 + \beta_1 \text{agegroup}_{ij} + \beta_2 \text{gender}_{ij} + \beta_3 \text{bmi}_{ij} + \gamma_{i0} + \gamma_{i1}\text{bmi} + \epsilon_{ij}\]</div><div>\[\epsilon_{ij}\]</div><p>is distributed with mean 0 variance <span>$\sigma^2_{\epsilon_{ij}}$</span></p><div>\[\gamma_{i} = (\gamma_{i0}, \gamma_{i1})\]</div><p>has mean <strong>0</strong> and variance <span>$\Sigma_\gamma$</span></p><div>\[\sigma^2_{\epsilon_{ij}} = exp(\tau_0 + \tau_1 \text{agegroup}_{ij} + \tau_2 \text{gender}_{ij} + \tau_3 \text{bmi}_{ij})\]</div><pre><code class="language-julia">vlmm = WSVarLmmModel(
    @formula(sbp ~ 1 + agegroup + gender + bmi_std + meds), 
    @formula(sbp ~ 1 + bmi_std), 
    @formula(sbp ~ 1 + agegroup + meds + bmi_std),
    :id, df);</code></pre><p>The <code>vlmm</code> object has the appropriate data. We can use the <code>fit!()</code> function to fit the model.</p><h2 id="Fit-model"><a class="docs-heading-anchor" href="#Fit-model">Fit model</a><a id="Fit-model-1"></a><a class="docs-heading-anchor-permalink" href="#Fit-model" title="Permalink"></a></h2><p>Main arguments of the <code>fit!()</code> function are:</p><ul><li><code>m::WSVarLmmModel</code>: The model to fit.</li><li><code>solver</code>: Non-linear programming solver to be used.</li><li><code>runs::Integer</code>: Number of weighted nonlinear least squares runs. Default is 2.</li></ul><p>For a complete documentation, type <code>?WSVarLmmModel</code> in Julia REPL.</p><article class="docstring"><header><a class="docstring-binding" id="WiSER.fit!" href="#WiSER.fit!"><code>WiSER.fit!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">fit!(m::WSVarLmmModel, 
solver=IpoptSolver(print_level=0, mehrotra_algorithm=&quot;yes&quot;, max_iter=100);
init=init_ls!(m), runs = 2)</code></pre><p>Fit a <code>WSVarLMMModel</code> object using a weighted NLS method.</p><p><strong>Positional arguments</strong></p><ul><li><code>m::WSVarLmmModel</code>: Model to fit.</li><li><code>solver</code>: Nonlinear programming solver to use. Common choices include:  <ul><li><code>Ipopt.IpoptSolver(print_level=0, mehrotra_algorithm=&quot;yes&quot;, max_iter=100)</code>.</li><li><code>Ipopt.IpoptSolver(print_level=0, mehrotra_algorithm=&quot;yes&quot;, warm_start_init_point=&quot;yes&quot;, max_iter=100)</code>.</li><li><code>Ipopt.IpoptSolver(print_level=0, watchdog_shortened_iter_trigger=3, max_iter=100)</code>.</li><li><code>KNITRO.KnitroSolver(outlev=3)</code>. (Knitro is commercial software)</li><li><code>NLopt.NLoptSolver(algorithm=:LD_MMA, maxeval=4000)</code>.  </li><li><code>NLopt.NLoptSolver(algorithm=:LD_LBFGS, maxeval=4000)</code>.</li></ul></li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>init</code>: Initialization strategy. <code>fit!</code> will use <code>m.τ</code> and <code>m.Lγ</code> to set the    weight matrices <code>Vi</code> and solve the weighted NLS to obtain an   estimate for <code>m.β</code>, <code>m.τ</code>, and <code>m.Lγ</code>.  Choices for <code>init</code> include  <ul><li><code>init_ls!(m)</code> (default): initialize by the least squares analytical solution.  </li><li><code>init_mom!(m)</code>: initialize by the unweighted NLS (MoM).  </li><li><code>m</code>: initilize from user supplied values in <code>m.τ</code> and <code>m.Lγ</code>.</li></ul></li><li><code>runs::Integer</code>: Number of weighted NLS runs; default is 2. Each run will use the    newest <code>m.τ</code> and <code>m.Lγ</code> to update the weight matrices <code>Vi</code> and solve the    new weighted NLS.</li><li><code>parallel::Bool</code>: Multi-threading or not. Default is <code>false</code>. </li><li><code>verbose::Bool</code>: Verbose display or not, Default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/OpenMendel/WiSER.jl/blob/6c5d86c93f3b6d38ec6ab3e32b66f51e08cda0a1/src/fit.jl#L1-L30">source</a></section></article><pre><code class="language-julia">WiSER.fit!(vlmm)</code></pre><pre><code class="language-none">******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit http://projects.coin-or.org/Ipopt
******************************************************************************

run = 1, ‖Δβ‖ = 0.037311, ‖Δτ‖ = 0.166678, ‖ΔL‖ = 0.100999, status = Optimal, time(s) = 0.425396
run = 2, ‖Δβ‖ = 0.005220, ‖Δτ‖ = 0.006748, ‖ΔL‖ = 0.048735, status = Optimal, time(s) = 0.354986






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
───────────────────────────────────────────────────────────
                     Estimate  Std. Error       Z  Pr(&gt;|Z|)
───────────────────────────────────────────────────────────
β1: (Intercept)   106.308       0.14384    739.07    &lt;1e-99
β2: agegroup       14.9844      0.0633245  236.63    &lt;1e-99
β3: gender: Male   10.0749      0.100279   100.47    &lt;1e-99
β4: bmi_std         0.296424    0.0139071   21.31    &lt;1e-99
β5: meds: OnMeds  -10.1107      0.122918   -82.26    &lt;1e-99
τ1: (Intercept)    -2.5212      0.393792    -6.40    &lt;1e-9
τ2: agegroup        1.50759     0.135456    11.13    &lt;1e-28
τ3: meds: OnMeds   -0.435225    0.0621076   -7.01    &lt;1e-11
τ4: bmi_std         0.0052695   0.0224039    0.24    0.8140
───────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  1.00196    0.0181387
 &quot;γ2: bmi_std&quot;      0.0181387  0.000549357</code></pre><p>The estimated coefficients and random effects covariance parameters can be retrieved by</p><pre><code class="language-julia">coef(vlmm)</code></pre><pre><code class="language-none">9-element Array{Float64,1}:
 106.30828661757685
  14.984423626292854
  10.074886642511625
   0.2964238570056824
 -10.110677648545206
  -2.5211956122809442
   1.5075882029978345
  -0.4352249760976689
   0.00526950183272128</code></pre><p>or individually</p><pre><code class="language-julia">vlmm.β</code></pre><pre><code class="language-none">5-element Array{Float64,1}:
 106.30828661757685
  14.984423626292854
  10.074886642511625
   0.2964238570056824
 -10.110677648545206</code></pre><pre><code class="language-julia">vlmm.τ</code></pre><pre><code class="language-none">4-element Array{Float64,1}:
 -2.5211956122809442
  1.5075882029978345
 -0.4352249760976689
  0.00526950183272128</code></pre><pre><code class="language-julia">vlmm.Σγ</code></pre><pre><code class="language-none">2×2 Array{Float64,2}:
 1.00196    0.0181387
 0.0181387  0.000549357</code></pre><p>The variance-covariance matrix of the estimated parameters (β, τ, Lγ) can be rerieved by</p><pre><code class="language-julia">vlmm.vcov</code></pre><pre><code class="language-none">12×12 Array{Float64,2}:
  0.0206899    -0.00753187   -0.00618382   …  -0.000123531   0.0644858
 -0.00753187    0.00400999    0.000152994      4.07896e-5   -0.0194226
 -0.00618382    0.000152994   0.0100558        4.35497e-5   -0.0299542
  5.60981e-5   -4.80751e-5    0.000108448      8.06623e-6    0.00149567
 -0.00311952   -0.000362412   0.00122535      -7.1571e-5     0.0168424
 -0.00652959    0.00207365    0.00276734   …   0.00217472   -1.70443
  0.00229271   -0.000743467  -0.000951293     -0.000740359   0.58213
 -0.000719608   0.000263081   0.000294779      0.000197117  -0.152908
  3.10756e-5    1.70391e-5   -0.00011849      -5.50781e-5    0.0266044
  0.000166021  -3.24178e-6   -0.00011537       9.0954e-6    -0.00139559
 -0.000123531   4.07896e-5    4.35497e-5   …   7.84536e-5   -0.0244586
  0.0644858    -0.0194226    -0.0299542       -0.0244586    19.1312</code></pre><h2 id="Tips-for-improving-estimation"><a class="docs-heading-anchor" href="#Tips-for-improving-estimation">Tips for improving estimation</a><a id="Tips-for-improving-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Tips-for-improving-estimation" title="Permalink"></a></h2><p><code>fit!</code> may fail due to various reasons. Often it indicates ill-conditioned data or an inadequate model. Following strategies may improve the fit. </p><h3 id="Standardize-continuous-predictors"><a class="docs-heading-anchor" href="#Standardize-continuous-predictors">Standardize continuous predictors</a><a id="Standardize-continuous-predictors-1"></a><a class="docs-heading-anchor-permalink" href="#Standardize-continuous-predictors" title="Permalink"></a></h3><p>In above example, we used the standardardized <code>bmi</code>. If we used the original <code>bmi</code> variable, the estimates of τ are instable, reflected by the large standard errors.</p><pre><code class="language-julia"># using unscaled bmi causes ill-conditioning
vlmm_bmi = WSVarLmmModel(
    @formula(sbp ~ 1 + agegroup + gender + bmi + meds), 
    @formula(sbp ~ 1 + bmi), 
    @formula(sbp ~ 1 + agegroup + meds + bmi),
    :id, df);
WiSER.fit!(vlmm_bmi)</code></pre><pre><code class="language-none">run = 1, ‖Δβ‖ = 0.208950, ‖Δτ‖ = 0.445610, ‖ΔL‖ = 2.027674, status = Optimal, time(s) = 0.876796
run = 2, ‖Δβ‖ = 0.032012, ‖Δτ‖ = 0.014061, ‖ΔL‖ = 0.780198, status = Optimal, time(s) = 0.987205






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
────────────────────────────────────────────────────────────
                      Estimate  Std. Error       Z  Pr(&gt;|Z|)
────────────────────────────────────────────────────────────
β1: (Intercept)   100.131        0.319906   313.00    &lt;1e-99
β2: agegroup       14.9844       0.0633245  236.63    &lt;1e-99
β3: gender: Male   10.0749       0.100279   100.47    &lt;1e-99
β4: bmi             0.246808     0.0115793   21.31    &lt;1e-99
β5: meds: OnMeds  -10.1107       0.122918   -82.26    &lt;1e-99
τ1: (Intercept)    -2.63101     17.2804      -0.15    0.8790
τ2: agegroup        1.50759      5.69286      0.26    0.7911
τ3: meds: OnMeds   -0.435225     1.37021     -0.32    0.7508
τ4: bmi             0.00438748   0.0281074    0.16    0.8760
────────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  0.484542    0.00557087
 &quot;γ2: bmi&quot;          0.00557087  0.000380843</code></pre><h3 id="Increase-runs"><a class="docs-heading-anchor" href="#Increase-runs">Increase <code>runs</code></a><a id="Increase-runs-1"></a><a class="docs-heading-anchor-permalink" href="#Increase-runs" title="Permalink"></a></h3><p>Increasing <code>runs</code> (default is 2) takes more computing resources but can be useful to get more precise estimates. If we set <code>runs=3</code> when using original <code>bmi</code> (ill-conditioned), the estimated τ are more accurate. The estimate of Σγ is still off though.</p><pre><code class="language-julia"># improve estimates from ill-conditioned data by more runs
WiSER.fit!(vlmm_bmi, runs=3)</code></pre><pre><code class="language-none">run = 1, ‖Δβ‖ = 0.208950, ‖Δτ‖ = 0.445610, ‖ΔL‖ = 2.027674, status = Optimal, time(s) = 0.850399
run = 2, ‖Δβ‖ = 0.032012, ‖Δτ‖ = 0.014061, ‖ΔL‖ = 0.780198, status = Optimal, time(s) = 1.060520
run = 3, ‖Δβ‖ = 0.008059, ‖Δτ‖ = 0.099534, ‖ΔL‖ = 0.696869, status = Optimal, time(s) = 1.127406






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
─────────────────────────────────────────────────────────────
                       Estimate  Std. Error       Z  Pr(&gt;|Z|)
─────────────────────────────────────────────────────────────
β1: (Intercept)   100.139         0.315745   317.15    &lt;1e-99
β2: agegroup       14.9839        0.0633172  236.65    &lt;1e-99
β3: gender: Male   10.0753        0.10027    100.48    &lt;1e-99
β4: bmi             0.246528      0.0114083   21.61    &lt;1e-99
β5: meds: OnMeds  -10.1109        0.122778   -82.35    &lt;1e-99
τ1: (Intercept)    -2.53158       0.866855    -2.92    0.0035
τ2: agegroup        1.50917       0.031734    47.56    &lt;1e-99
τ3: meds: OnMeds   -0.436745      0.0513571   -8.50    &lt;1e-16
τ4: bmi             0.000277851   0.0363866    0.01    0.9939
─────────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  3.48717e-48  7.26846e-26
 &quot;γ2: bmi&quot;          7.26846e-26  0.00155716</code></pre><h3 id="Try-different-nonlinear-programming-(NLP)-solvers"><a class="docs-heading-anchor" href="#Try-different-nonlinear-programming-(NLP)-solvers">Try different nonlinear programming (NLP) solvers</a><a id="Try-different-nonlinear-programming-(NLP)-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Try-different-nonlinear-programming-(NLP)-solvers" title="Permalink"></a></h3><p>A different solver may remedy the issue. By default, <code>WiSER.jl</code> uses the <a href="https://github.com/jump-dev/Ipopt.jl">Ipopt</a> solver, but it can use any solver that supports <a href="https://github.com/JuliaOpt/MathProgBase.jl">MathProgBase.jl</a>. Check documentation of <code>fit!</code> for commonly used NLP solvers. In our experience, <a href="https://github.com/JuliaOpt/KNITRO.jl">Knitro.jl</a> works the best, but it is a commercial software.</p><pre><code class="language-julia"># print Ipopt iterates for diagnostics
WiSER.fit!(vlmm, Ipopt.IpoptSolver(print_level=5, mehrotra_algorithm=&quot;yes&quot;))</code></pre><pre><code class="language-none">This is Ipopt version 3.13.2, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       28

Total number of variables............................:        7
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  5.6575142e+04 0.00e+00 5.30e+04   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  3.4931954e+04 0.00e+00 1.43e+04 -11.0 2.07e+00    -  1.00e+00 1.00e+00f  1
   2  3.0285692e+04 0.00e+00 4.18e+03 -11.0 5.46e-01    -  1.00e+00 1.00e+00f  1
   3  2.9124181e+04 0.00e+00 1.87e+03 -11.0 2.78e-01    -  1.00e+00 1.00e+00f  1
   4  2.8571986e+04 0.00e+00 6.41e+02 -11.0 2.38e-01    -  1.00e+00 1.00e+00f  1
   5  2.8379415e+04 0.00e+00 1.62e+02 -11.0 2.91e-01    -  1.00e+00 1.00e+00f  1
   6  2.8328064e+04 0.00e+00 4.31e+01 -11.0 3.09e-01    -  1.00e+00 1.00e+00f  1
   7  2.8315452e+04 0.00e+00 1.13e+01 -11.0 3.02e-01    -  1.00e+00 1.00e+00f  1
   8  2.8312446e+04 0.00e+00 4.59e+00 -11.0 2.76e-01    -  1.00e+00 1.00e+00f  1
   9  2.8311807e+04 0.00e+00 1.87e+00 -11.0 2.28e-01    -  1.00e+00 1.00e+00f  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  2.8311705e+04 0.00e+00 5.50e-01 -11.0 1.52e-01    -  1.00e+00 1.00e+00f  1
  11  2.8311697e+04 0.00e+00 7.11e-02 -11.0 6.21e-02    -  1.00e+00 1.00e+00f  1
  12  2.8311697e+04 0.00e+00 1.34e-03 -11.0 8.86e-03    -  1.00e+00 1.00e+00f  1
  13  2.8311697e+04 0.00e+00 1.53e-05 -11.0 1.62e-04    -  1.00e+00 1.00e+00f  1
  14  2.8311697e+04 0.00e+00 2.18e-07 -11.0 8.29e-08    -  1.00e+00 1.00e+00f  1
  15  2.8311697e+04 0.00e+00 1.13e-08 -11.0 3.75e-10    -  1.00e+00 1.00e+00f  1
  16  2.8311697e+04 0.00e+00 3.05e-10 -11.0 2.12e-11    -  1.00e+00 1.00e+00f  1

Number of Iterations....: 16

                                   (scaled)                 (unscaled)
Objective...............:   1.6226171160601305e+04    2.8311697021847409e+04
Dual infeasibility......:   3.0454227901697596e-10    5.3137050315399392e-10
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   3.0454227901697596e-10    5.3137050315399392e-10


Number of objective function evaluations             = 17
Number of objective gradient evaluations             = 17
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 16
Total CPU secs in IPOPT (w/o function evaluations)   =      0.031
Total CPU secs in NLP function evaluations           =      0.346

EXIT: Optimal Solution Found.
run = 1, ‖Δβ‖ = 0.037311, ‖Δτ‖ = 0.166678, ‖ΔL‖ = 0.100999, status = Optimal, time(s) = 0.330199
This is Ipopt version 3.13.2, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       28

Total number of variables............................:        7
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  8.8973092e+04 0.00e+00 2.21e+05   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  4.3429572e+04 0.00e+00 6.17e+04 -11.0 2.38e+00    -  1.00e+00 1.00e+00f  1
   2  4.2299630e+04 0.00e+00 5.28e+04 -11.0 5.57e-01    -  1.00e+00 1.00e+00f  1
   3  3.2423451e+04 0.00e+00 1.96e+04 -11.0 5.34e-01    -  1.00e+00 1.00e+00f  1
   4  2.8893365e+04 0.00e+00 6.24e+03 -11.0 2.85e-01    -  1.00e+00 1.00e+00f  1
   5  2.7767774e+04 0.00e+00 2.56e+03 -11.0 2.67e-01    -  1.00e+00 1.00e+00f  1
   6  2.7349272e+04 0.00e+00 8.84e+02 -11.0 2.79e-01    -  1.00e+00 1.00e+00f  1
   7  2.7218041e+04 0.00e+00 2.32e+02 -11.0 3.08e-01    -  1.00e+00 1.00e+00f  1
   8  2.7182533e+04 0.00e+00 5.14e+01 -11.0 3.24e-01    -  1.00e+00 1.00e+00f  1
   9  2.7173294e+04 0.00e+00 1.62e+01 -11.0 3.27e-01    -  1.00e+00 1.00e+00f  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  2.7170863e+04 0.00e+00 8.25e+00 -11.0 3.25e-01    -  1.00e+00 1.00e+00f  1
  11  2.7170227e+04 0.00e+00 4.19e+00 -11.0 3.19e-01    -  1.00e+00 1.00e+00f  1
  12  2.7170063e+04 0.00e+00 2.08e+00 -11.0 3.09e-01    -  1.00e+00 1.00e+00f  1
  13  2.7170022e+04 0.00e+00 9.97e-01 -11.0 2.89e-01    -  1.00e+00 1.00e+00f  1
  14  2.7170013e+04 0.00e+00 4.38e-01 -11.0 2.53e-01    -  1.00e+00 1.00e+00f  1
  15  2.7170011e+04 0.00e+00 1.56e-01 -11.0 1.91e-01    -  1.00e+00 1.00e+00f  1
  16  2.7170011e+04 0.00e+00 3.31e-02 -11.0 1.04e-01    -  1.00e+00 1.00e+00f  1
  17  2.7170011e+04 0.00e+00 1.88e-03 -11.0 2.70e-02    -  1.00e+00 1.00e+00f  1
  18  2.7170011e+04 0.00e+00 1.49e-05 -11.0 1.57e-03    -  1.00e+00 1.00e+00f  1
  19  2.7170011e+04 0.00e+00 5.09e-07 -11.0 5.31e-06    -  1.00e+00 1.00e+00f  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  20  2.7170011e+04 0.00e+00 9.99e-09 -11.0 1.26e-08    -  1.00e+00 1.00e+00f  1

Number of Iterations....: 20

                                   (scaled)                 (unscaled)
Objective...............:   2.7170011141753250e+04    2.7170011141753250e+04
Dual infeasibility......:   9.9916355189577644e-09    9.9916355189577644e-09
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   9.9916355189577644e-09    9.9916355189577644e-09


Number of objective function evaluations             = 21
Number of objective gradient evaluations             = 21
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 20
Total CPU secs in IPOPT (w/o function evaluations)   =      0.020
Total CPU secs in NLP function evaluations           =      0.358

EXIT: Optimal Solution Found.
run = 2, ‖Δβ‖ = 0.005220, ‖Δτ‖ = 0.006748, ‖ΔL‖ = 0.048735, status = Optimal, time(s) = 0.384719






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
───────────────────────────────────────────────────────────
                     Estimate  Std. Error       Z  Pr(&gt;|Z|)
───────────────────────────────────────────────────────────
β1: (Intercept)   106.308       0.14384    739.07    &lt;1e-99
β2: agegroup       14.9844      0.0633245  236.63    &lt;1e-99
β3: gender: Male   10.0749      0.100279   100.47    &lt;1e-99
β4: bmi_std         0.296424    0.0139071   21.31    &lt;1e-99
β5: meds: OnMeds  -10.1107      0.122918   -82.26    &lt;1e-99
τ1: (Intercept)    -2.5212      0.393792    -6.40    &lt;1e-9
τ2: agegroup        1.50759     0.135456    11.13    &lt;1e-28
τ3: meds: OnMeds   -0.435225    0.0621076   -7.01    &lt;1e-11
τ4: bmi_std         0.0052695   0.0224039    0.24    0.8140
───────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  1.00196    0.0181387
 &quot;γ2: bmi_std&quot;      0.0181387  0.000549357</code></pre><pre><code class="language-julia"># use Knitro (require installation of Knitro software and Knitro.jl)
# Using KNITRO
# WiSER.fit!(vlmm, KNITRO.KnitroSolver(outlev=3));</code></pre><pre><code class="language-julia"># use NLopt
WiSER.fit!(vlmm, NLopt.NLoptSolver(algorithm=:LD_MMA, maxeval=4000))</code></pre><pre><code class="language-none">run = 1, ‖Δβ‖ = 0.037311, ‖Δτ‖ = 0.162196, ‖ΔL‖ = 0.100050, status = Optimal, time(s) = 0.571036
run = 2, ‖Δβ‖ = 0.005248, ‖Δτ‖ = 0.008742, ‖ΔL‖ = 0.001334, status = Optimal, time(s) = 0.185684






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
────────────────────────────────────────────────────────────
                      Estimate  Std. Error       Z  Pr(&gt;|Z|)
────────────────────────────────────────────────────────────
β1: (Intercept)   106.308        0.14384    739.07    &lt;1e-99
β2: agegroup       14.9844       0.0633238  236.63    &lt;1e-99
β3: gender: Male   10.0749       0.100277   100.47    &lt;1e-99
β4: bmi_std         0.296421     0.0139114   21.31    &lt;1e-99
β5: meds: OnMeds  -10.1106       0.122912   -82.26    &lt;1e-99
τ1: (Intercept)    -2.53263      0.102706   -24.66    &lt;1e-99
τ2: agegroup        1.51161      0.0388869   38.87    &lt;1e-99
τ3: meds: OnMeds   -0.435897     0.0524849   -8.31    &lt;1e-16
τ4: bmi_std         0.00576945   0.0218517    0.26    0.7918
────────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  1.00228    0.0179118
 &quot;γ2: bmi_std&quot;      0.0179118  0.00441753</code></pre><h3 id="Try-different-starting-points"><a class="docs-heading-anchor" href="#Try-different-starting-points">Try different starting points</a><a id="Try-different-starting-points-1"></a><a class="docs-heading-anchor-permalink" href="#Try-different-starting-points" title="Permalink"></a></h3><p>Initialization matters as well. By default, <code>fit!</code> uses a crude least squares estimate as the starting point. We can also try a method of moment estimate or user-supplied values.</p><pre><code class="language-julia"># MoM starting point
WiSER.fit!(vlmm, init = init_mom!(vlmm))</code></pre><pre><code class="language-none">run = 1, ‖Δβ‖ = 0.036245, ‖Δτ‖ = 0.188207, ‖ΔL‖ = 0.127483, status = Optimal, time(s) = 0.256069
run = 2, ‖Δβ‖ = 0.006798, ‖Δτ‖ = 0.009128, ‖ΔL‖ = 0.050049, status = Optimal, time(s) = 0.340028






Within-subject variance estimation by robust regression (WiSER)
Number of individuals/clusters: 500
Total observations: 5011

Fixed-effects parameters:
────────────────────────────────────────────────────────────
                      Estimate  Std. Error       Z  Pr(&gt;|Z|)
────────────────────────────────────────────────────────────
β1: (Intercept)   106.308        0.143831   739.12    &lt;1e-99
β2: agegroup       14.9846       0.063327   236.62    &lt;1e-99
β3: gender: Male   10.0747       0.100282   100.46    &lt;1e-99
β4: bmi_std         0.296596     0.013989    21.20    &lt;1e-99
β5: meds: OnMeds  -10.1107       0.122973   -82.22    &lt;1e-99
τ1: (Intercept)    -2.52233      0.218068   -11.57    &lt;1e-30
τ2: agegroup        1.5079       0.0759423   19.86    &lt;1e-87
τ3: meds: OnMeds   -0.434951     0.0549139   -7.92    &lt;1e-14
τ4: bmi_std         0.00527178   0.0220323    0.24    0.8109
────────────────────────────────────────────────────────────
Random effects covariance matrix Σγ:
 &quot;γ1: (Intercept)&quot;  1.00193    0.0180064
 &quot;γ2: bmi_std&quot;      0.0180064  0.000967577</code></pre><pre><code class="language-julia"># user-supplied starting point in vlmm.β, vlmm.τ, vlmm.Lγ
# WiSER.fit!(vlmm, init = vlmm)</code></pre><h2 id="Simulating-responses"><a class="docs-heading-anchor" href="#Simulating-responses">Simulating responses</a><a id="Simulating-responses-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-responses" title="Permalink"></a></h2><p>The <code>rvarlmm()</code> and <code>rvarlmm!()</code> functions can be used to generate a respone from user-supplied data and parameters. The <code>rand!()</code> command can be used to overwrite the response in a VarLmmModel object based on the parameters and optional user-supplied distribution.   </p><p>The <code>rand!(m::WSVarLmmModel; respdist = MvNormal, γωdist = MvNormal, Σγω = [], kwargs...)</code> function replaces the responses <code>m.data[i].y</code> with a simulated response based on:</p><ul><li>The data in the model object&#39;s data <code>X, Z, W</code> matrices. </li><li>The parameter values in the model.</li><li>The condistribution distribution of the response given the random effects.</li><li>The distribution of the random effects.</li><li>If simulating from MvTDistribution, you must specify the degrees of freedom via <code>df = x</code>.</li></ul><p>The <code>rvarlmm()</code> takes arrays of matricies of the data in addition to the reponse. It generates a simulated response from the VarLMM model based on:</p><ul><li><code>Xs</code>: array of each clusters <code>X</code>: mean fixed effects covariates</li><li><code>Zs</code>: array of each clusters <code>Z</code>: random location effects covariates</li><li><code>Ws</code>: array of each clusters <code>W</code>: within-subject variance fixed effects covariates</li><li><code>β</code>: mean fixed effects vector</li><li><code>τ</code>: within-subject variance fixed effects vector</li><li><code>respdist</code>: the distribution for response. Default is MvNormal. </li><li><code>Σγ</code>: random location effects covariance matrix. </li><li><code>Σγω</code>: joint random location and random scale effects covariance matrix (if generating from full model).</li><li>If simulating from MvTDistribution, you must specify the degrees of freedom via <code>df = x</code>.</li></ul><p>The <code>rvarlmm!()</code> function can be used to generate a simulated response from the VarLMM model based on a datatable and place the generated response into the datatable with the <code>respname</code> field. </p><p>Note: <strong>the datatable MUST be ordered by grouping variable for it to generate in the correct order.</strong> This can be checked via <code>datatable == sort(datatable, idvar)</code>. The response is based on:</p><ul><li><code>meanformula</code>: represents the formula for the mean fixed effects <code>β</code> (variables in X matrix)</li><li><code>reformula</code>: represents the formula for the mean random effects γ (variables in Z matrix)</li><li><code>wsvarformula</code>: represents the formula for the within-subject variance fixed effects τ (variables in W matrix)</li><li><code>idvar</code>: the id variable for groupings.</li><li><code>datatable</code>: the data table holding all of the data for the model. For this function it <strong>must be in order</strong>.</li><li><code>β</code>: mean fixed effects vector</li><li><code>τ</code>: within-subject variance fixed effects vector</li><li><code>respdist</code>: the distribution for response. Default is MvNormal. </li><li><code>Σγ</code>: random location effects covariance matrix. </li><li><code>Σγω</code>: joint random location and random scale effects covariance matrix (if generating from full model)</li><li><code>respname</code>: symbol representing the simulated response variable name.</li><li>If simulating from MvTDistribution, you must specify the degrees of freedom via <code>df = x</code>.</li></ul><p>For both functions, only one of the Σγ or Σγω matrices have to be specified in order to use the function. Σγ can be used to specify that the generative model will not include a random scale component. It outputs <code>ys</code>: an array of reponse <code>y</code> that match the order of the data arrays (<code>Xs, Zs, Ws</code>).</p><pre><code class="language-julia">@show vlmm.data[1].y
Random.seed!(123)
WiSER.rand!(vlmm; respdist = MvNormal) 
@show vlmm.data[1].y</code></pre><pre><code class="language-none">(vlmm.data[1]).y = [159.58635186701068, 161.84850248386945, 160.48359574389164, 161.13448128282593, 165.44341004850986, 160.05302471176626, 162.1001598920002, 163.1526453898974, 166.6749897477845]
(vlmm.data[1]).y = [163.18878816959145, 161.92583955740076, 160.66341989866248, 165.16516161135553, 162.25415689993756, 163.00335025501857, 162.06896794235755, 161.4110226386001, 160.57277004398432]





9-element Array{Float64,1}:
 163.18878816959145
 161.92583955740076
 160.66341989866248
 165.16516161135553
 162.25415689993756
 163.00335025501857
 162.06896794235755
 161.4110226386001
 160.57277004398432</code></pre><pre><code class="language-julia">t = table((id = [1; 1; 2; 3; 3; 3; 4], y = randn(7),
x1 = ones(7), x2 = randn(7), x3 = randn(7), z1 = ones(7),
z2 = randn(7), w1 = ones(7), w2 = randn(7), w3 = randn(7)))
df = DataFrame(t)

f1 = @formula(y ~ 1 + x2 + x3)
f2 = @formula(y ~ 1 + z2)
f3 = @formula(y ~ 1 + w2 + w3)

β = zeros(3)
τ = zeros(3)
Σγ = [1. 0.; 0. 1.]

first(df, 3)</code></pre><p>&lt;table class=&quot;data-frame&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;id&lt;/th&gt;&lt;th&gt;y&lt;/th&gt;&lt;th&gt;x1&lt;/th&gt;&lt;th&gt;x2&lt;/th&gt;&lt;th&gt;x3&lt;/th&gt;&lt;th&gt;z1&lt;/th&gt;&lt;th&gt;z2&lt;/th&gt;&lt;th&gt;w1&lt;/th&gt;&lt;th&gt;w2&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Int64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;3 rows × 10 columns (omitted printing of 1 columns)&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1.54783&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.268209&lt;/td&gt;&lt;td&gt;-0.0571664&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.222619&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;1.17759&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0.365508&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;1.17666&lt;/td&gt;&lt;td&gt;-0.204264&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;1.0579&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.431064&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;-0.31447&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.453137&lt;/td&gt;&lt;td&gt;-0.402403&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-1.65662&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-0.216927&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</p><pre><code class="language-julia">rvarlmm!(f1, f2, f3, :id, df, β, τ;
        Σγ = Σγ, respname = :response)
df[!, :response]</code></pre><pre><code class="language-none">7-element Array{Float64,1}:
 -1.1362274345153838
 -2.0396426949163917
 -3.0297957994022724
  0.7967897326514723
  1.1225160002462085
  1.2517509664063533
  0.34088047862482207</code></pre><p>Note: JuliaDB&#39;s <code>IndexedTables</code> elements cannot be mutated. If you use the <code>rvarlmm!()</code> function with a JuliaDB table, you must reassign the <code>datatable</code> to the output as shown below:</p><pre><code class="language-julia">t = rvarlmm!(f1, f2, f3, :id, t, β, τ;
        Σγ = Σγ, respname = :response)</code></pre><pre><code class="language-none">Table with 7 rows, 11 columns:
Columns:
[1m#   [22m[1mcolname   [22m[1mtype[22m
─────────────────────
1   id        Int64
2   y         Float64
3   x1        Float64
4   x2        Float64
5   x3        Float64
6   z1        Float64
7   z2        Float64
8   w1        Float64
9   w2        Float64
10  w3        Float64
11  response  Float64</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 21 July 2020 10:36">Tuesday 21 July 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
